
@article{barrosSurveyEmbeddingDynamic2021,
  title = {A {{Survey}} on {{Embedding Dynamic Graphs}}},
  author = {Barros, Claudio D. T. and Mendon{\c c}a, Matheus R. F. and Vieira, Alex B. and Ziviani, Artur},
  year = {2021},
  month = jan,
  journal = {arXiv:2101.01229 [cs]},
  eprint = {2101.01229},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Embedding static graphs in low-dimensional vector spaces plays a key role in network analytics and inference, supporting applications like node classification, link prediction, and graph visualization. However, many real-world networks present dynamic behavior, including topological evolution, feature evolution, and diffusion. Therefore, several methods for embedding dynamic graphs have been proposed to learn network representations over time, facing novel challenges, such as time-domain modeling, temporal features to be captured, and the temporal granularity to be embedded. In this survey, we overview dynamic graph embedding, discussing its fundamentals and the recent advances developed so far. We introduce the formal definition of dynamic graph embedding, focusing on the problem setting and introducing a novel taxonomy for dynamic graph embedding input and output. We further explore different dynamic behaviors that may be encompassed by embeddings, classifying by topological evolution, feature evolution, and processes on networks. Afterward, we describe existing techniques and propose a taxonomy for dynamic graph embedding techniques based on algorithmic approaches, from matrix and tensor factorization to deep learning, random walks, and temporal point processes. We also elucidate main applications, including dynamic link prediction, anomaly detection, and diffusion prediction, and we further state some promising research directions in the area.},
  archiveprefix = {arXiv},
  keywords = {37E25 (Primary) 68T30; 05C62; 58D10 (Secondary),A.1,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,I.2.6},
  note = {Comment: 40 pages, 10 figures},
  file = {C\:\\Users\\terng\\Zotero\\storage\\9HFG3744\\Barros et al_2021_A Survey on Embedding Dynamic Graphs.pdf;C\:\\Users\\terng\\Zotero\\storage\\J72JAMRS\\2101.html}
}

@article{barrosSurveyEmbeddingDynamic2023,
  title = {A {{Survey}} on {{Embedding Dynamic Graphs}}},
  author = {Barros, Claudio D. T. and Mendon{\c c}a, Matheus R. F. and Vieira, Alex B. and Ziviani, Artur},
  year = {2023},
  month = jan,
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {1},
  pages = {1--37},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3483595},
  abstract = {Embedding static graphs in low-dimensional vector spaces plays a key role in network analytics and inference, supporting applications like node classification, link prediction, and graph visualization. However, many real-world networks present dynamic behavior, including topological evolution, feature evolution, and diffusion. Therefore, several methods for embedding dynamic graphs have been proposed to learn network representations over time, facing novel challenges, such as time-domain modeling, temporal features to be captured, and the temporal granularity to be embedded. In this survey, we overview dynamic graph embedding, discussing its fundamentals and the recent advances developed so far. We introduce the formal definition of dynamic graph embedding, focusing on the problem setting and introducing a novel taxonomy for dynamic graph embedding input and output. We further explore different dynamic behaviors that may be encompassed by embeddings, classifying by topological evolution, feature evolution, and processes on networks. Afterward, we describe existing techniques and propose a taxonomy for dynamic graph embedding techniques based on algorithmic approaches, from matrix and tensor factorization to deep learning, random walks, and temporal point processes. We also elucidate main applications, including dynamic link prediction, anomaly detection, and diffusion prediction, and we further state some promising research directions in the area.},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\EFI9W2LG\\3483595.pdf}
}

@misc{C3founderOverview,
  title = {C3founder - {{Overview}}},
  journal = {GitHub},
  abstract = {c3founder has 4 repositories available. Follow their code on GitHub.},
  howpublished = {https://github.com/c3founder},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\7LQZJJB4\\c3founder.html}
}

@article{chenPrioritizingAllocationCOVID192021,
  title = {Prioritizing Allocation of {{COVID-19}} Vaccines Based on Social Contacts Increases Vaccination Effectiveness},
  author = {Chen, Jiangzhuo and Hoops, Stefan and Marathe, Achla and Mortveit, Henning and Lewis, Bryan and Venkatramanan, Srinivasan and Haddadan, Arash and Bhattacharya, Parantapa and Adiga, Abhijin and Vullikanti, Anil},
  year = {2021},
  journal = {medRxiv},
  publisher = {{Cold Spring Harbor Laboratory Press}},
  file = {C\:\\Users\\terng\\Zotero\\storage\\DHZ7NNEW\\Chen et al. - 2021 - Prioritizing allocation of COVID-19 vaccines based.pdf;C\:\\Users\\terng\\Zotero\\storage\\V7B2MKYK\\2021.02.04.html}
}

@misc{datavisboblarameeHowReadScientific2016,
  title = {How {{To Read}} a {{Scientific Research Paper}}: {{Extracting}} the {{Essentials}}},
  shorttitle = {How {{To Read}} a {{Scientific Research Paper}}},
  author = {{DataVisBob Laramee}},
  year = {2016},
  month = nov,
  abstract = {23,425 views \textbullet{} Nov 11, 2016 \textbullet{} Abstract PhD students or researchers starting a new research project or initiating work in an unfamiliar research direction often undertake a scientific literature search in order to inform themselves with respect to a chosen topic. This start-up phase involves wading through and reading scores, if not hundreds, of research papers that have already been published in the area of interest. Reading a large quantity of scientific papers and capturing the essential information from them is a very challenging task. Furthermore, this difficulty only increases with the passage of time as the complexity of literature increases as well as the quantity of publications. This lecture aims to instruct a starting PhD candidate or researcher on how to read a scientific research paper. By ``read'' we mean extracting the essential, most important information from a (previously) published scientific conference or journal paper. During the course of a PhD, the candidate will read many research papers containing a vast amount of information. However, it is not possible to remember all of the details presented, nor is it necessary. Here we identify and describe the essential knowledge that is best extracted and summarized when reading a research paper. Robert S. Laramee, How to Read a Visualization Research Paper: Extracting the Essentials, IEEE Computer Graphics and Applications (IEEE CG\&amp;A), Vol. 31, No. 3, May/June 2011, pages 78-82 PDF http://cs.swan.ac.uk/\textasciitilde csbob/research/... DOI http://dx.doi.org/10.1109/MCG.2011.44 Connect with DataVis Bob on Facebook: https://www.facebook.com/datavisbob Here is a version of the talk with slides: https://youtu.be/Q7ruNLUEMFg And yet another one with slides: https://youtu.be/IUlHgORKyQE                   Show less                   Show more}
}

@article{daveTCLRTemporalContrastive2021,
  title = {{{TCLR}}: {{Temporal Contrastive Learning}} for {{Video Representation}}},
  shorttitle = {{{TCLR}}},
  author = {Dave, Ishan and Gupta, Rohit and Rizve, Mamshad Nayeem and Shah, Mubarak},
  year = {2021},
  month = apr,
  journal = {arXiv:2101.07974 [cs]},
  eprint = {2101.07974},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Contrastive learning has nearly closed the gap between supervised and self-supervised learning of image representations, and has also been explored for videos. However, prior work on contrastive learning for video data has not explored the effect of explicitly encouraging the features to be distinct across the temporal dimension. We develop a new temporal contrastive learning framework consisting of two novel losses to improve upon existing contrastive self-supervised video representation learning methods. The local-local temporal contrastive loss adds the task of discriminating between non-overlapping clips from the same video, whereas the global-local temporal contrastive aims to discriminate between timesteps of the feature map of an input clip in order to increase the temporal diversity of the learned features. Our proposed temporal contrastive learning framework achieves significant improvement over the state-of-the-art results in various downstream video understanding tasks such as action recognition, limited-label action classification, and nearest-neighbor video retrieval on multiple video datasets and backbones. We also demonstrate significant improvement in fine-grained action classification for visually similar classes. With the commonly used 3D ResNet-18 architecture, we achieve 82.4\% (+5.1\% increase over the previous best) top-1 accuracy on UCF101 and 52.9\% (+5.4\% increase) on HMDB51 action classification, and 56.2\% (+11.7\% increase) Top-1 Recall on UCF101 nearest neighbor video retrieval.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\terng\\Zotero\\storage\\5ERMXPS2\\Dave et al_2021_TCLR.pdf;C\:\\Users\\terng\\Zotero\\storage\\6BZK6A7M\\2101.html}
}

@article{daveTCLRTemporalContrastive2021a,
  title = {{{TCLR}}: {{Temporal Contrastive Learning}} for {{Video Representation}}},
  shorttitle = {{{TCLR}}},
  author = {Dave, Ishan and Gupta, Rohit and Rizve, Mamshad Nayeem and Shah, Mubarak},
  year = {2021},
  month = apr,
  journal = {arXiv:2101.07974 [cs]},
  eprint = {2101.07974},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Contrastive learning has nearly closed the gap between supervised and self-supervised learning of image representations, and has also been explored for videos. However, prior work on contrastive learning for video data has not explored the effect of explicitly encouraging the features to be distinct across the temporal dimension. We develop a new temporal contrastive learning framework consisting of two novel losses to improve upon existing contrastive self-supervised video representation learning methods. The local-local temporal contrastive loss adds the task of discriminating between non-overlapping clips from the same video, whereas the global-local temporal contrastive aims to discriminate between timesteps of the feature map of an input clip in order to increase the temporal diversity of the learned features. Our proposed temporal contrastive learning framework achieves significant improvement over the state-of-the-art results in various downstream video understanding tasks such as action recognition, limited-label action classification, and nearest-neighbor video retrieval on multiple video datasets and backbones. We also demonstrate significant improvement in fine-grained action classification for visually similar classes. With the commonly used 3D ResNet-18 architecture, we achieve 82.4\% (+5.1\% increase over the previous best) top-1 accuracy on UCF101 and 52.9\% (+5.4\% increase) on HMDB51 action classification, and 56.2\% (+11.7\% increase) Top-1 Recall on UCF101 nearest neighbor video retrieval.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\terng\\Zotero\\storage\\ZF7FNCS6\\Dave et al. - 2021 - TCLR Temporal Contrastive Learning for Video Repr.pdf}
}

@article{daveTCLRTemporalContrastive2021b,
  title = {{{TCLR}}: {{Temporal Contrastive Learning}} for {{Video Representation}}},
  shorttitle = {{{TCLR}}},
  author = {Dave, Ishan and Gupta, Rohit and Rizve, Mamshad Nayeem and Shah, Mubarak},
  year = {2021},
  month = apr,
  journal = {arXiv:2101.07974 [cs]},
  eprint = {2101.07974},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Contrastive learning has nearly closed the gap between supervised and self-supervised learning of image representations, and has also been explored for videos. However, prior work on contrastive learning for video data has not explored the effect of explicitly encouraging the features to be distinct across the temporal dimension. We develop a new temporal contrastive learning framework consisting of two novel losses to improve upon existing contrastive self-supervised video representation learning methods. The local-local temporal contrastive loss adds the task of discriminating between non-overlapping clips from the same video, whereas the global-local temporal contrastive aims to discriminate between timesteps of the feature map of an input clip in order to increase the temporal diversity of the learned features. Our proposed temporal contrastive learning framework achieves significant improvement over the state-of-the-art results in various downstream video understanding tasks such as action recognition, limited-label action classification, and nearest-neighbor video retrieval on multiple video datasets and backbones. We also demonstrate significant improvement in fine-grained action classification for visually similar classes. With the commonly used 3D ResNet-18 architecture, we achieve 82.4\% (+5.1\% increase over the previous best) top-1 accuracy on UCF101 and 52.9\% (+5.4\% increase) on HMDB51 action classification, and 56.2\% (+11.7\% increase) Top-1 Recall on UCF101 nearest neighbor video retrieval.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\terng\\Zotero\\storage\\6896PK4N\\Dave et al. - 2021 - TCLR Temporal Contrastive Learning for Video Repr.pdf}
}

@article{daveTCLRTemporalContrastive2021c,
  title = {{{TCLR}}: {{Temporal Contrastive Learning}} for {{Video Representation}}},
  shorttitle = {{{TCLR}}},
  author = {Dave, Ishan and Gupta, Rohit and Rizve, Mamshad Nayeem and Shah, Mubarak},
  year = {2021},
  month = apr,
  journal = {arXiv:2101.07974 [cs]},
  eprint = {2101.07974},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Contrastive learning has nearly closed the gap between supervised and self-supervised learning of image representations, and has also been explored for videos. However, prior work on contrastive learning for video data has not explored the effect of explicitly encouraging the features to be distinct across the temporal dimension. We develop a new temporal contrastive learning framework consisting of two novel losses to improve upon existing contrastive self-supervised video representation learning methods. The local-local temporal contrastive loss adds the task of discriminating between non-overlapping clips from the same video, whereas the global-local temporal contrastive aims to discriminate between timesteps of the feature map of an input clip in order to increase the temporal diversity of the learned features. Our proposed temporal contrastive learning framework achieves significant improvement over the state-of-the-art results in various downstream video understanding tasks such as action recognition, limited-label action classification, and nearest-neighbor video retrieval on multiple video datasets and backbones. We also demonstrate significant improvement in fine-grained action classification for visually similar classes. With the commonly used 3D ResNet-18 architecture, we achieve 82.4\% (+5.1\% increase over the previous best) top-1 accuracy on UCF101 and 52.9\% (+5.4\% increase) on HMDB51 action classification, and 56.2\% (+11.7\% increase) Top-1 Recall on UCF101 nearest neighbor video retrieval.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\terng\\Zotero\\storage\\ZU52NKFP\\Dave et al_2021_TCLR.pdf;C\:\\Users\\terng\\Zotero\\storage\\8KDYC2HW\\2101.html}
}

@article{eubankModelingDiseaseOutbreaks2004,
  title = {Modeling {{Disease Outbreaks}} in {{Realistic Urban Social Networks}}},
  author = {Eubank, Stephen and Guclu, Hasan and Kumar, Sritesh and Marathe, Madhav and Srinivasan, Aravind and Toroczkai, Zoltan and Wang, Nan},
  year = {2004},
  month = jun,
  journal = {Nature},
  volume = {429},
  pages = {180--4},
  doi = {10.1038/nature02541},
  abstract = {Most mathematical models for the spread of disease use differential equations based on uniform mixing assumptions or ad hoc models for the contact process. Here we explore the use of dynamic bipartite graphs to model the physical contact patterns that result from movements of individuals between specific locations. The graphs are generated by large-scale individual-based urban traffic simulations built on actual census, land-use and population-mobility data. We find that the contact network among people is a strongly connected small-world-like graph with a well-defined scale for the degree distribution. However, the locations graph is scale-free, which allows highly efficient outbreak detection by placing sensors in the hubs of the locations network. Within this large-scale simulation framework, we then analyse the relative merits of several proposed mitigation strategies for smallpox spread. Our results suggest that outbreaks can be contained by a strategy of targeted vaccination combined with early detection without resorting to mass vaccination of a population.},
  file = {C\:\\Users\\terng\\Zotero\\storage\\GN6KRILM\\Eubank et al_2004_Modeling Disease Outbreaks in Realistic Urban Social Networks.pdf}
}

@article{funkModellingInfluenceHuman2010,
  title = {Modelling the Influence of Human Behaviour on the Spread of Infectious Diseases: A Review},
  author = {Funk, Sebastian and Salathe, Marcel and Jansen, Vincent A A},
  year = {2010},
  journal = {J. R. Soc. Interface},
  pages = {10},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\UFXFWYVF\\Funk et al. - 2010 - Modelling the influence of human behaviour on the .pdf}
}

@article{grosContainmentEfficiencyControl2021,
  title = {Containment Efficiency and Control Strategies for the {{Corona}} Pandemic Costs},
  author = {Gros, Claudius and Valenti, Roser and Schneider, Lukas and Valenti, Kilian and Gros, Daniel},
  year = {2021},
  month = dec,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  eprint = {2004.00493},
  eprinttype = {arxiv},
  pages = {6848},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-86072-x},
  abstract = {The rapid spread of the Coronavirus (COVID-19) confronts policy makers with the problem of measuring the effectiveness of containment strategies, balancing public health considerations with the economic costs of social distancing measures. We introduce a modified epidemic model that we name the controlled-SIR model, in which the disease reproduction rate evolves dynamically in response to political and societal reactions. An analytic solution is presented. The model reproduces official COVID-19 cases counts of a large number of regions and countries that surpassed the first peak of the outbreak. A single unbiased feedback parameter is extracted from field data and used to formulate an index that measures the efficiency of containment strategies (the CEI index). CEI values for a range of countries are given. For two variants of the controlled-SIR model, detailed estimates of the total medical and socio-economic costs are evaluated over the entire course of the epidemic. Costs comprise medical care cost, the economic cost of social distancing, as well as the economic value of lives saved. Under plausible parameters, strict measures fare better than a hands-off policy. Strategies based on current case numbers lead to substantially higher total costs than strategies based on the overall history of the epidemic.},
  archiveprefix = {arXiv},
  keywords = {Economics - General Economics,Physics - Physics and Society,Quantitative Biology - Populations and Evolution},
  note = {Comment: Scientific Reports, in press},
  file = {C\:\\Users\\terng\\Zotero\\storage\\MRR2WCWC\\Gros et al_2021_Containment efficiency and control strategies for the Corona pandemic costs.pdf;C\:\\Users\\terng\\Zotero\\storage\\K94QET6A\\2004.html}
}

@article{hwangSelfsupervisedAuxiliaryLearning2021,
  title = {Self-Supervised {{Auxiliary Learning}} with {{Meta-paths}} for {{Heterogeneous Graphs}}},
  author = {Hwang, Dasol and Park, Jinyoung and Kwon, Sunyoung and Kim, Kyung-Min and Ha, Jung-Woo and Kim, Hyunwoo J.},
  year = {2021},
  month = feb,
  journal = {arXiv:2007.08294 [cs, stat]},
  eprint = {2007.08294},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Graph neural networks have shown superior performance in a wide range of applications providing a powerful representation of graph-structured data. Recent works show that the representation can be further improved by auxiliary tasks. However, the auxiliary tasks for heterogeneous graphs, which contain rich semantic information with various types of nodes and edges, have less explored in the literature. In this paper, to learn graph neural networks on heterogeneous graphs we propose a novel self-supervised auxiliary learning method using meta-paths, which are composite relations of multiple edge types. Our proposed method is learning to learn a primary task by predicting meta-paths as auxiliary tasks. This can be viewed as a type of meta-learning. The proposed method can identify an effective combination of auxiliary tasks and automatically balance them to improve the primary task. Our methods can be applied to any graph neural networks in a plug-in manner without manual labeling or additional data. The experiments demonstrate that the proposed method consistently improves the performance of link prediction and node classification on heterogeneous graphs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  note = {Comment: Neural Information Processing Systems (NeurIPS), 2020},
  file = {C\:\\Users\\terng\\Zotero\\storage\\SC5IDAVF\\Hwang et al_2021_Self-supervised Auxiliary Learning with Meta-paths for Heterogeneous Graphs.pdf;C\:\\Users\\terng\\Zotero\\storage\\R67HKFWK\\2007.html}
}

@misc{IEEEXploreFullText,
  title = {{{IEEE Xplore Full-Text PDF}}:},
  howpublished = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9439502},
  file = {C\:\\Users\\terng\\Zotero\\storage\\3KURZ2BD\\stamp.html}
}

@article{jiangGraphNeuralNetwork2021,
  title = {Graph {{Neural Network}} for {{Traffic Forecasting}}: {{A Survey}}},
  shorttitle = {Graph {{Neural Network}} for {{Traffic Forecasting}}},
  author = {Jiang, Weiwei and Luo, Jiayun},
  year = {2021},
  month = feb,
  journal = {arXiv:2101.11174 [cs]},
  eprint = {2101.11174},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Traffic forecasting is important for the success of intelligent transportation systems. Deep learning models, including convolution neural networks and recurrent neural networks, have been extensively applied in traffic forecasting problems to model spatial and temporal dependencies. In recent years, to model the graph structures in transportation systems as well as contextual information, graph neural networks have been introduced and have achieved state-of-the-art performance in a series of traffic forecasting problems. In this survey, we review the rapidly growing body of research using different graph neural networks, e.g. graph convolutional and graph attention networks, in various traffic forecasting problems, e.g. road traffic flow and speed forecasting, passenger flow forecasting in urban rail transit systems, and demand forecasting in ride-hailing platforms. We also present a comprehensive list of open data and source resources for each problem and identify future research directions. To the best of our knowledge, this paper is the first comprehensive survey that explores the application of graph neural networks for traffic forecasting problems. We have also created a public GitHub repository where the latest papers, open data, and source resources will be updated.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\terng\\Zotero\\storage\\QSIZVSW7\\Jiang_Luo_2021_Graph Neural Network for Traffic Forecasting.pdf;C\:\\Users\\terng\\Zotero\\storage\\FEXKRRQQ\\2101.html}
}

@article{jinSelfsupervisedLearningGraphs2020,
  title = {Self-Supervised {{Learning}} on {{Graphs}}: {{Deep Insights}} and {{New Direction}}},
  shorttitle = {Self-Supervised {{Learning}} on {{Graphs}}},
  author = {Jin, Wei and Derr, Tyler and Liu, Haochen and Wang, Yiqi and Wang, Suhang and Liu, Zitao and Tang, Jiliang},
  year = {2020},
  month = jun,
  journal = {arXiv:2006.10141 [cs, stat]},
  eprint = {2006.10141},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {The success of deep learning notoriously requires larger amounts of costly annotated data. This has led to the development of self-supervised learning (SSL) that aims to alleviate this limitation by creating domain specific pretext tasks on unlabeled data. Simultaneously, there are increasing interests in generalizing deep learning to the graph domain in the form of graph neural networks (GNNs). GNNs can naturally utilize unlabeled nodes through the simple neighborhood aggregation that is unable to thoroughly make use of unlabeled nodes. Thus, we seek to harness SSL for GNNs to fully exploit the unlabeled data. Different from data instances in the image and text domains, nodes in graphs present unique structure information and they are inherently linked indicating not independent and identically distributed (or i.i.d.). Such complexity is a double-edged sword for SSL on graphs. On the one hand, it determines that it is challenging to adopt solutions from the image and text domains to graphs and dedicated efforts are desired. On the other hand, it provides rich information that enables us to build SSL from a variety of perspectives. Thus, in this paper, we first deepen our understandings on when, why, and which strategies of SSL work with GNNs by empirically studying numerous basic SSL pretext tasks on graphs. Inspired by deep insights from the empirical studies, we propose a new direction SelfTask to build advanced pretext tasks that are able to achieve state-of-the-art performance on various real-world datasets. The specific experimental settings to reproduce our results can be found in \textbackslash url\{https://github.com/ChandlerBang/SelfTask-GNN\}.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\terng\\Zotero\\storage\\5S942GHU\\Jin et al_2020_Self-supervised Learning on Graphs.pdf;C\:\\Users\\terng\\Zotero\\storage\\YRGQHTSG\\2006.html}
}

@article{kazemiRepresentationLearningDynamica,
  title = {Representation Learning for Dynamic Graphs A Survey},
  author = {Kazemi, Seyed Mehran and Goel, Rishab and Jain, Kshitij and Kobyzev, Ivan and Sethi, Akshay and Forsyth, Peter and Poupart, Pascal},
  pages = {73},
  abstract = {Graphs arise naturally in many real-world applications including social networks, recommender systems, ontologies, biology, and computational finance. Traditionally, machine learning models for graphs have been mostly designed for static graphs. However, many applications involve evolving graphs. This introduces important challenges for learning and inference since nodes, attributes, and edges change over time. In this survey, we review the recent advances in representation learning for dynamic graphs, including dynamic knowledge graphs. We describe existing models from an encoder-decoder perspective, categorize these encoders and decoders based on the techniques they employ, and analyze the approaches in each category. We also review several prominent applications and widely used datasets and highlight directions for future research.},
  langid = {english},
  file = {Representation Learning for Dynamic Graphs A Survey.pdf}
}

@article{kivelaMultilayerNetworks2014,
  title = {Multilayer {{Networks}}},
  author = {Kivel{\"a}, Mikko and Arenas, Alexandre and Barthelemy, Marc and Gleeson, James P. and Moreno, Yamir and Porter, Mason A.},
  year = {2014},
  month = sep,
  journal = {Journal of Complex Networks},
  volume = {2},
  number = {3},
  eprint = {1309.7233},
  eprinttype = {arxiv},
  pages = {203--271},
  issn = {2051-1310, 2051-1329},
  doi = {10.1093/comnet/cnu016},
  abstract = {In most natural and engineered systems, a set of entities interact with each other in complicated patterns that can encompass multiple types of relationships, change in time, and include other types of complications. Such systems include multiple subsystems and layers of connectivity, and it is important to take such "multilayer" features into account to try to improve our understanding of complex systems. Consequently, it is necessary to generalize "traditional" network theory by developing (and validating) a framework and associated tools to study multilayer systems in a comprehensive fashion. The origins of such efforts date back several decades and arose in multiple disciplines, and now the study of multilayer networks has become one of the most important directions in network science. In this paper, we discuss the history of multilayer networks (and related concepts) and review the exploding body of work on such networks. To unify the disparate terminology in the large body of recent work, we discuss a general framework for multilayer networks, construct a dictionary of terminology to relate the numerous existing concepts to each other, and provide a thorough discussion that compares, contrasts, and translates between related notions such as multilayer networks, multiplex networks, interdependent networks, networks of networks, and many others. We also survey and discuss existing data sets that can be represented as multilayer networks. We review attempts to generalize single-layer-network diagnostics to multilayer networks. We also discuss the rapidly expanding research on multilayer-network models and notions like community structure, connected components, tensor decompositions, and various types of dynamical processes on multilayer networks. We conclude with a summary and an outlook.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society},
  note = {Comment: Working paper; 59 pages, 8 figures},
  file = {C\:\\Users\\terng\\Zotero\\storage\\ZPRIVIXC\\Kivelä et al_2014_Multilayer Networks.pdf;C\:\\Users\\terng\\Zotero\\storage\\6ANS99EB\\1309.html}
}

@inproceedings{kumarPredictingDynamicEmbedding2019,
  title = {Predicting {{Dynamic Embedding Trajectory}} in {{Temporal Interaction Networks}}},
  booktitle = {Proceedings of the 25th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Kumar, Srijan and Zhang, Xikun and Leskovec, Jure},
  year = {2019},
  month = jul,
  pages = {1269--1278},
  publisher = {{ACM}},
  address = {{Anchorage AK USA}},
  doi = {10.1145/3292500.3330895},
  isbn = {978-1-4503-6201-6},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\YRPKQCEV\\Kumar et al. - 2019 - Predicting Dynamic Embedding Trajectory in Tempora.pdf}
}

@article{liuGraphSelfSupervisedLearning2021,
  title = {Graph {{Self-Supervised Learning}}: {{A Survey}}},
  shorttitle = {Graph {{Self-Supervised Learning}}},
  author = {Liu, Yixin and Pan, Shirui and Jin, Ming and Zhou, Chuan and Xia, Feng and Yu, Philip S.},
  year = {2021},
  month = aug,
  journal = {arXiv:2103.00111 [cs]},
  eprint = {2103.00111},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Deep learning on graphs has attracted significant interests recently. However, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. To address these issues, self-supervised learning (SSL), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. Different from SSL on other domains like computer vision and natural language processing, SSL on graphs has an exclusive background, design ideas, and taxonomies. Under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ SSL techniques for graph data. We construct a unified framework that mathematically formalizes the paradigm of graph SSL. According to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. We further conclude the applications of graph SSL across various research fields and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph SSL. Finally, we discuss the remaining challenges and potential future directions in this research field.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  note = {Comment: 25 pages, 8 figures, 9 tables},
  file = {/mnt/c/Users/terng/Zotero/storage/U9DL5UMR/Liu et al_2021_Graph Self-Supervised Learning.pdf}
}

@article{liuGraphSelfSupervisedLearning2021a,
  title = {Graph {{Self-Supervised Learning}}: {{A Survey}}},
  shorttitle = {Graph {{Self-Supervised Learning}}},
  author = {Liu, Yixin and Pan, Shirui and Jin, Ming and Zhou, Chuan and Xia, Feng and Yu, Philip S.},
  year = {2021},
  month = aug,
  journal = {arXiv:2103.00111 [cs]},
  eprint = {2103.00111},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Deep learning on graphs has attracted significant interests recently. However, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. To address these issues, self-supervised learning (SSL), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. Different from SSL on other domains like computer vision and natural language processing, SSL on graphs has an exclusive background, design ideas, and taxonomies. Under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ SSL techniques for graph data. We construct a unified framework that mathematically formalizes the paradigm of graph SSL. According to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. We further conclude the applications of graph SSL across various research fields and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph SSL. Finally, we discuss the remaining challenges and potential future directions in this research field.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  note = {Comment: 25 pages, 8 figures, 9 tables},
  file = {C\:\\Users\\terng\\Zotero\\storage\\93VP5E6I\\Liu et al_2021_Graph Self-Supervised Learning.pdf;C\:\\Users\\terng\\Zotero\\storage\\9BQ4C7GK\\2103.html}
}

@article{opolkaSpatioTemporalDeepGraph2019,
  title = {Spatio-{{Temporal Deep Graph Infomax}}},
  author = {Opolka, Felix L. and Solomon, Aaron and Cangea, C{\u a}t{\u a}lina and Veli{\v c}kovi{\'c}, Petar and Li{\`o}, Pietro and Hjelm, R. Devon},
  year = {2019},
  month = apr,
  journal = {arXiv:1904.06316 [cs, stat]},
  eprint = {1904.06316},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Spatio-temporal graphs such as traffic networks or gene regulatory systems present challenges for the existing deep learning methods due to the complexity of structural changes over time. To address these issues, we introduce Spatio-Temporal Deep Graph Infomax (STDGI)---a fully unsupervised node representation learning approach based on mutual information maximization that exploits both the temporal and spatial dynamics of the graph. Our model tackles the challenging task of node-level regression by training embeddings to maximize the mutual information between patches of the graph, at any given time step, and between features of the central nodes of patches, in the future. We demonstrate through experiments and qualitative studies that the learned representations can successfully encode relevant information about the input graph and improve the predictive performance of spatio-temporal auto-regressive forecasting models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  note = {Comment: 6 pages, 2 figures, Representation Learning on Graphs and Manifolds Workshop of the International Conference on Learning Representations (ICLR)},
  file = {C\:\\Users\\terng\\Zotero\\storage\\WWPWZUPD\\Opolka et al_2019_Spatio-Temporal Deep Graph Infomax.pdf;C\:\\Users\\terng\\Zotero\\storage\\8QTXA8D4\\1904.html}
}

@misc{OrgzlyNotesToDo,
  title = {Orgzly | {{Notes}} \& {{To-Do Lists}}},
  howpublished = {http://www.orgzly.com/help}
}

@article{panVideoMoCoContrastiveVideo,
  title = {{{VideoMoCo}}: {{Contrastive Video Representation Learning With Temporally Adversarial Examples}}},
  author = {Pan, Tian and Song, Yibing and Yang, Tianyu and Jiang, Wenhao and Liu, Wei},
  pages = {10},
  abstract = {MoCo [11] is effective for unsupervised image representation learning. In this paper, we propose VideoMoCo for unsupervised video representation learning. Given a video sequence as an input sample, we improve the temporal feature representations of MoCo from two perspectives. First, we introduce a generator to drop out several frames from this sample temporally. The discriminator is then learned to encode similar feature representations regardless of frame removals. By adaptively dropping out different frames during training iterations of adversarial learning, we augment this input sample to train a temporally robust encoder. Second, we use temporal decay to model key attenuation in the memory queue when computing the contrastive loss. As the momentum encoder updates after keys enqueue, the representation ability of these keys degrades when we use the current input sample for contrastive learning. This degradation is reflected via temporal decay to attend the input sample to recent keys in the queue. As a result, we adapt MoCo to learn video representations without empirically designing pretext tasks. By empowering the temporal robustness of the encoder and modeling the temporal decay of the keys, our VideoMoCo improves MoCo temporally based on contrastive learning. Experiments on benchmark datasets including UCF101 and HMDB51 show that VideoMoCo stands as a state-of-the-art video representation learning method.},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\JZNNFUZ6\\Pan et al. - VideoMoCo Contrastive Video Representation Learni.pdf}
}

@article{qianSpatiotemporalContrastiveVideo2021,
  title = {Spatiotemporal {{Contrastive Video Representation Learning}}},
  author = {Qian, Rui and Meng, Tianjian and Gong, Boqing and Yang, Ming-Hsuan and Wang, Huisheng and Belongie, Serge and Cui, Yin},
  year = {2021},
  month = apr,
  journal = {arXiv:2008.03800 [cs]},
  eprint = {2008.03800},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {We present a self-supervised Contrastive Video Representation Learning (CVRL) method to learn spatiotemporal visual representations from unlabeled videos. Our representations are learned using a contrastive loss, where two augmented clips from the same short video are pulled together in the embedding space, while clips from different videos are pushed away. We study what makes for good data augmentations for video self-supervised learning and find that both spatial and temporal information are crucial. We carefully design data augmentations involving spatial and temporal cues. Concretely, we propose a temporally consistent spatial augmentation method to impose strong spatial augmentations on each frame of the video while maintaining the temporal consistency across frames. We also propose a sampling-based temporal augmentation method to avoid overly enforcing invariance on clips that are distant in time. On Kinetics-600, a linear classifier trained on the representations learned by CVRL achieves 70.4\% top-1 accuracy with a 3D-ResNet-50 (R3D-50) backbone, outperforming ImageNet supervised pre-training by 15.7\% and SimCLR unsupervised pre-training by 18.8\% using the same inflated R3D-50. The performance of CVRL can be further improved to 72.9\% with a larger R3D-152 (2x filters) backbone, significantly closing the gap between unsupervised and supervised video representation learning. Our code and models will be available at https://github.com/tensorflow/models/tree/master/official/.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  note = {Comment: CVPR2021 Camera ready},
  file = {C\:\\Users\\terng\\Zotero\\storage\\YG4RDCS2\\Qian et al_2021_Spatiotemporal Contrastive Video Representation Learning.pdf;C\:\\Users\\terng\\Zotero\\storage\\IJCUZJ3B\\2008.html}
}

@article{rossiTemporalGraphNetworks2020,
  title = {Temporal {{Graph Networks}} for {{Deep Learning}} on {{Dynamic Graphs}}},
  author = {Rossi, Emanuele and Chamberlain, Ben and Frasca, Fabrizio and Eynard, Davide and Monti, Federico and Bronstein, Michael},
  year = {2020},
  month = oct,
  journal = {arXiv:2006.10637 [cs, stat]},
  eprint = {2006.10637},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Graph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn complex systems of relations or interactions arising in a broad spectrum of problems ranging from biology and particle physics to social networks and recommendation systems. Despite the plethora of different models for deep learning on graphs, few approaches have been proposed thus far for dealing with graphs that present some sort of dynamic nature (e.g. evolving features or connectivity over time). In this paper, we present Temporal Graph Networks (TGNs), a generic, efficient framework for deep learning on dynamic graphs represented as sequences of timed events. Thanks to a novel combination of memory modules and graph-based operators, TGNs are able to significantly outperform previous approaches being at the same time more computationally efficient. We furthermore show that several previous models for learning on dynamic graphs can be cast as specific instances of our framework. We perform a detailed ablation study of different components of our framework and devise the best configuration that achieves state-of-the-art performance on several transductive and inductive prediction tasks for dynamic graphs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\terng\\Zotero\\storage\\NJF25URL\\Rossi et al_2020_Temporal Graph Networks for Deep Learning on Dynamic Graphs.pdf;C\:\\Users\\terng\\Zotero\\storage\\W9ISWITL\\2006.html}
}

@inproceedings{sambaturuDesigningEffectivePractical2020,
  title = {Designing Effective and Practical Interventions to Contain Epidemics},
  booktitle = {Proceedings of the 19th {{International Conference}} on {{Autonomous Agents}} and {{MultiAgent Systems}}},
  author = {Sambaturu, Prathyush and Adhikari, Bijaya and Prakash, B. Aditya and Venkatramanan, Srinivasan and Vullikanti, Anil},
  year = {2020},
  pages = {1187--1195},
  note = {\textbf{Extracted Annotations (5/20/2021, 1:11:14 PM)}
\par
"outbreak. This is a challenging stochastic optimization problem. We design a bicriteria approximation algorithm, which combines a linear programming based rounding, along with the sample average approximation technique. Our approach also provides the empirical approximation factor for the problem instance, relative to the optimum. We find that the approximation factor" (\href{zotero://open-pdf/library/items/THPDTH54?page=1}{Sambaturu et al 2020:1187})
\par
"available budget" (\href{zotero://open-pdf/library/items/THPDTH54?page=1}{Sambaturu et al 2020:1187})
\par
"(in state S) with transmission probability 푝 (푢, 푣 ) (or 푝 , if this is uniform for all edges); this" (\href{zotero://open-pdf/library/items/THPDTH54?page=1}{Sambaturu et al 2020:1187})
\par
"vaccination strategies to minimize the expected ) . outbreak size in an SIR epidemic process on a network = 퐺 푉 , 퐸 ( There is a lot of relevant prior work on this topic, and can be split along the following lines: (1) Optimization" (\href{zotero://open-pdf/library/items/THPDTH54?page=1}{Sambaturu et al 2020:1187})},
  file = {C\:\\Users\\terng\\Zotero\\storage\\THPDTH54\\Sambaturu et al. - 2020 - Designing effective and practical interventions to.pdf}
}

@article{shaoMultiLevelGraphContrastive2021,
  title = {Multi-{{Level Graph Contrastive Learning}}},
  author = {Shao, Pengpeng and Liu, Tong and Zhang, Dawei and Tao, Jianhua and Che, Feihu and Yang, Guohua},
  year = {2021},
  month = jul,
  journal = {arXiv:2107.02639 [cs]},
  eprint = {2107.02639},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Graph representation learning has attracted a surge of interest recently, whose target at learning discriminant embedding for each node in the graph. Most of these representation methods focus on supervised learning and heavily depend on label information. However, annotating graphs are expensive to obtain in the real world, especially in specialized domains (i.e. biology), as it needs the annotator to have the domain knowledge to label the graph. To approach this problem, self-supervised learning provides a feasible solution for graph representation learning. In this paper, we propose a Multi-Level Graph Contrastive Learning (MLGCL) framework for learning robust representation of graph data by contrasting space views of graphs. Specifically, we introduce a novel contrastive view - topological and feature space views. The original graph is first-order approximation structure and contains uncertainty or error, while the \$k\$NN graph generated by encoding features preserves high-order proximity. Thus \$k\$NN graph generated by encoding features not only provide a complementary view, but is more suitable to GNN encoder to extract discriminant representation. Furthermore, we develop a multi-level contrastive mode to preserve the local similarity and semantic similarity of graph-structured data simultaneously. Extensive experiments indicate MLGCL achieves promising results compared with the existing state-of-the-art graph representation learning methods on seven datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\terng\\Zotero\\storage\\GSXEZGR6\\Shao et al_2021_Multi-Level Graph Contrastive Learning.pdf;C\:\\Users\\terng\\Zotero\\storage\\2P8SIHTA\\2107.html}
}

@article{skardingFoundationsModelingDynamic2021,
  title = {Foundations and {{Modeling}} of {{Dynamic Networks Using Dynamic Graph Neural Networks}}: {{A Survey}}},
  shorttitle = {Foundations and {{Modeling}} of {{Dynamic Networks Using Dynamic Graph Neural Networks}}},
  author = {Skarding, Joakim and Gabrys, Bogdan and Musial, Katarzyna},
  year = {2021},
  journal = {IEEE Access},
  volume = {9},
  pages = {79143--79168},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3082932},
  abstract = {Dynamic networks are used in a wide range of fields, including social network analysis, recommender systems and epidemiology. Representing complex networks as structures changing over time allow network models to leverage not only structural but also temporal patterns. However, as dynamic network literature stems from diverse fields and makes use of inconsistent terminology, it is challenging to navigate. Meanwhile, graph neural networks (GNNs) have gained a lot of attention in recent years for their ability to perform well on a range of network science tasks, such as link prediction and node classification. Despite the popularity of graph neural networks and the proven benefits of dynamic network models, there has been little focus on graph neural networks for dynamic networks. To address the challenges resulting from the fact that this research crosses diverse fields as well as to survey dynamic graph neural networks, this work is split into two main parts. First, to address the ambiguity of the dynamic network terminology we establish a foundation of dynamic networks with consistent, detailed terminology and notation. Second, we present a comprehensive survey of dynamic graph neural network models using the proposed terminology.},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\XQJ8XKNM\\Skarding et al. - 2021 - Foundations and Modeling of Dynamic Networks Using.pdf}
}

@article{tomyEstimatingStateEpidemics2021,
  title = {Estimating the {{State}} of {{Epidemics Spreading}} with {{Graph Neural Networks}}},
  author = {Tomy, Abhishek and Razzanelli, Matteo and Di Lauro, Francesco and Rus, Daniela and Della Santina, Cosimo},
  year = {2021},
  month = may,
  journal = {arXiv:2105.05060 [physics, q-bio]},
  eprint = {2105.05060},
  eprinttype = {arxiv},
  primaryclass = {physics, q-bio},
  abstract = {When an epidemic spreads into a population, it is often unpractical or impossible to have a continuous monitoring of all subjects involved. As an alternative, algorithmic solutions can be used to infer the state of the whole population from a limited amount of measures. We analyze the capability of deep neural networks to solve this challenging task. Our proposed architecture is based on Graph Convolutional Neural Networks. As such it can reason on the effect of the underlying social network structure, which is recognized as the main component in the spreading of an epidemic. We test the proposed architecture with two scenarios modeled on the CoVid-19 pandemic: a generic homogeneous population, and a toy model of Boston metropolitan area.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Physics - Physics and Society,Quantitative Biology - Populations and Evolution},
  note = {Comment: 15 pages, 7 figures},
  file = {C\:\\Users\\terng\\Zotero\\storage\\JZLKYNZA\\Tomy et al_2021_Estimating the State of Epidemics Spreading with Graph Neural Networks.pdf;C\:\\Users\\terng\\Zotero\\storage\\SQSTPKAN\\2105.html}
}

@article{venkatramananUsingDatadrivenAgentbased2018,
  title = {Using Data-Driven Agent-Based Models for Forecasting Emerging Infectious Diseases},
  author = {Venkatramanan, Srinivasan and Lewis, Bryan and Chen, Jiangzhuo and Higdon, Dave and Vullikanti, Anil and Marathe, Madhav},
  year = {2018},
  month = mar,
  journal = {Epidemics},
  series = {The {{RAPIDD Ebola Forecasting Challenge}}},
  volume = {22},
  pages = {43--49},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2017.02.010},
  abstract = {Producing timely, well-informed and reliable forecasts for an ongoing epidemic of an emerging infectious disease is a huge challenge. Epidemiologists and policy makers have to deal with poor data quality, limited understanding of the disease dynamics, rapidly changing social environment and the uncertainty on effects of various interventions in place. Under this setting, detailed computational models provide a comprehensive framework for integrating diverse data sources into a well-defined model of disease dynamics and social behavior, potentially leading to better understanding and actions. In this paper, we describe one such agent-based model framework developed for forecasting the 2014\textendash 2015 Ebola epidemic in Liberia, and subsequently used during the Ebola forecasting challenge. We describe the various components of the model, the calibration process and summarize the forecast performance across scenarios of the challenge. We conclude by highlighting how such a data-driven approach can be refined and adapted for future epidemics, and share the lessons learned over the course of the challenge.},
  langid = {english},
  keywords = {Agent-based models,Bayesian calibration,Ebola,Emerging infectious diseases,Simulation optimization},
  file = {C\:\\Users\\terng\\Zotero\\storage\\E7VVYTZG\\Venkatramanan et al_2018_Using data-driven agent-based models for forecasting emerging infectious.pdf;C\:\\Users\\terng\\Zotero\\storage\\KX3I2HSM\\S1755436517300221.html}
}

@misc{voitExampleStory2021,
  title = {Example {{Story}}},
  author = {Voit, Karl},
  year = {2021},
  month = oct,
  abstract = {What did I do on February 14th 2007? Visualize your (digital) life in Org-mode},
  copyright = {GPL-3.0},
  keywords = {emacs,email,files,filesystem,git,org-mode,orgmode,personal-information-management,pim,python,quantified-self,search}
}

@article{voitWhatReallyHappened,
  title = {What Really Happened on {{September}} 15th 2008? {{Getting The Most}} from {{Your Personal Information}} with {{Memacs}}},
  author = {Voit, Karl},
  pages = {6},
  abstract = {Combining and summarizing meta-data from various kinds of data sources is one possible solution to the data fragmentation we are suffering from. Multiple projects have addressed this issue already. This paper presents a new approach named Memacs. It automatically generates a detailed linked diary of our digital artifacts scattered across local files of multiple formats as well as data silos of the internet. Being elegantly simple and open, Memacs uses already existing visualization features of GNU Emacs and Org-mode to provide a promising platform for life-logging, Quantified Self movement, and people looking for advanced Personal Information Management (PIM) in general.},
  langid = {english},
  keywords = {pkm},
  file = {C\:\\Users\\terng\\Zotero\\storage\\HY8LCX8B\\Voit - What really happened on September 15th 2008 Getti.pdf}
}

@article{wuComprehensiveSurveyGraph2021,
  title = {A {{Comprehensive Survey}} on {{Graph Neural Networks}}},
  author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  year = {2021},
  month = jan,
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {32},
  number = {1},
  eprint = {1901.00596},
  eprinttype = {arxiv},
  pages = {4--24},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2020.2978386},
  abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  note = {Comment: Minor revision (updated tables and references)},
  file = {C\:\\Users\\terng\\Zotero\\storage\\2328JB9Y\\Wu et al_2021_A Comprehensive Survey on Graph Neural Networks.pdf;C\:\\Users\\terng\\Zotero\\storage\\QVHHDD42\\1901.html}
}

@article{youGraphContrastiveLearning2021,
  title = {Graph {{Contrastive Learning}} with {{Augmentations}}},
  author = {You, Yuning and Chen, Tianlong and Sui, Yongduo and Chen, Ting and Wang, Zhangyang and Shen, Yang},
  year = {2021},
  month = apr,
  journal = {arXiv:2010.13902 [cs]},
  eprint = {2010.13902},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Generalizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are less explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework for learning unsupervised representations of graph data. We first design four types of graph augmentations to incorporate various priors. We then systematically study the impact of various combinations of graph augmentations on multiple datasets, in four different settings: semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in preliminary experiments. Our codes are available at https://github.com/Shen-Lab/GraphCL.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  note = {Comment: Supplementary materials are available at https://yyou1996.github.io/files/neurips2020\_graphcl\_supplement.pdf. NeurIPS 2020},
  file = {C\:\\Users\\terng\\Zotero\\storage\\7NKPHFTN\\You et al_2021_Graph Contrastive Learning with Augmentations.pdf;C\:\\Users\\terng\\Zotero\\storage\\HE9RGLDG\\2010.html}
}

@article{yuanSurveyTrafficPrediction2021,
  title = {A {{Survey}} of {{Traffic Prediction}}: From {{Spatio-Temporal Data}} to {{Intelligent Transportation}}},
  shorttitle = {A {{Survey}} of {{Traffic Prediction}}},
  author = {Yuan, Haitao and Li, Guoliang},
  year = {2021},
  month = mar,
  journal = {Data Science and Engineering},
  volume = {6},
  number = {1},
  pages = {63--85},
  issn = {2364-1541},
  doi = {10.1007/s41019-020-00151-z},
  abstract = {Intelligent transportation (e.g., intelligent traffic light) makes our travel more convenient and efficient. With the development of mobile Internet and position technologies, it is reasonable to collect spatio-temporal data and then leverage these data to achieve the goal of intelligent transportation, and here, traffic prediction plays an important role. In this paper, we provide a comprehensive survey on traffic prediction, which is from the spatio-temporal data layer to the intelligent transportation application layer. At first, we split the whole research scope into four parts from bottom to up, where the four parts are, respectively, spatio-temporal data, preprocessing, traffic prediction and traffic application. Later, we review existing work on the four parts. First, we summarize traffic data into five types according to their difference on spatial and temporal dimensions. Second, we focus on four significant data preprocessing techniques: map-matching, data cleaning, data storage and data compression. Third, we focus on three kinds of traffic prediction problems (i.e., classification, generation and estimation/forecasting). In particular, we summarize the challenges and discuss how existing methods address these challenges. Fourth, we list five typical traffic applications. Lastly, we provide emerging research challenges and opportunities. We believe that the survey can help the partitioners to understand existing traffic prediction problems and methods, which can further encourage them to solve their intelligent transportation applications.},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\SKDX4KH9\\Yuan_Li_2021_A Survey of Traffic Prediction.pdf}
}

@article{zhangPreTrainingDynamicGraph2021,
  title = {Pre-{{Training}} on {{Dynamic Graph Neural Networks}}},
  author = {Zhang, Jiajun and Chen, Kejia and Wang, Yunyun},
  year = {2021},
  month = feb,
  journal = {arXiv:2102.12380 [cs]},
  eprint = {2102.12380},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {The pre-training on the graph neural network model can learn the general features of large-scale networks or networks of the same type by self-supervised methods, which allows the model to work even when node labels are missing. However, the existing pre-training methods do not take network evolution into consideration. This paper proposes a pre-training method on dynamic graph neural networks (PT-DGNN), which uses dynamic attributed graph generation tasks to simultaneously learn the structure, semantics, and evolution features of the graph. The method includes two steps: 1) dynamic sub-graph sampling, and 2) pre-training with dynamic attributed graph generation task. Comparative experiments on three realistic dynamic network datasets show that the proposed method achieves the best results on the link prediction fine-tuning task.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {C\:\\Users\\terng\\Zotero\\storage\\NRFBXRH7\\Zhang et al_2021_Pre-Training on Dynamic Graph Neural Networks.pdf;C\:\\Users\\terng\\Zotero\\storage\\MGUQJQIK\\2102.html}
}

@article{zinoAnalysisPredictionControl2021,
  title = {Analysis, {{Prediction}}, and {{Control}} of {{Epidemics}}: {{A Survey}} from {{Scalar}} to {{Dynamic Network Models}}},
  shorttitle = {Analysis, {{Prediction}}, and {{Control}} of {{Epidemics}}},
  author = {Zino, Lorenzo and Cao, Ming},
  year = {2021},
  month = feb,
  journal = {arXiv:2103.00181 [cs, eess, math]},
  eprint = {2103.00181},
  eprinttype = {arxiv},
  primaryclass = {cs, eess, math},
  abstract = {During the ongoing COVID-19 pandemic, mathematical models of epidemic spreading have emerged as powerful tools to produce valuable predictions of the evolution of the pandemic, helping public health authorities decide which intervention policies should be implemented. The study of these models -- grounded in the systems theory and often analyzed using control-theoretic tools -- is an extremely important research area for many researchers from different fields, including epidemiology, engineering, physics, mathematics, computer science, sociology, economics, and management. In this survey, we review the history and present the state of the art in the modeling, analysis, and control of epidemic dynamics. We discuss different approaches to epidemic modeling, either deterministic or stochastic, ranging from the first implementations of scalar systems of differential equations to describing the epidemic spreading at the population level, and to more recent models on dynamic networks, which capture the spatial spread and the time-varying nature of human interactions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Social and Information Networks,Electrical Engineering and Systems Science - Systems and Control,graph protection,Mathematics - Dynamical Systems,Mathematics - Optimization and Control},
  note = {Comment: 38 pages, 11 figures. Accepted for publication in the IEEE Circuits and Systems Magazine (\textbackslash c\{opyright\} 2021 IEEE)},
  file = {C\:\\Users\\terng\\Zotero\\storage\\P3RPI55F\\Zino and Cao - 2021 - Analysis, Prediction, and Control of Epidemics A .pdf;C\:\\Users\\terng\\Zotero\\storage\\8DIKNV83\\2103.html}
}

@misc{zreeonGettingThingsOutside2016,
  type = {Reddit {{Post}}},
  title = {Getting Things from Outside {{Emacs}} into Org-Mode/{{Emacs}}},
  author = {{zreeon}},
  year = {2016},
  month = dec,
  journal = {r/emacs},
  file = {C\:\\Users\\terng\\Zotero\\storage\\6HWLSJHF\\getting_things_from_outside_emacs_into.html}
}

@article{skarding2021benchmarking,
  title={Benchmarking Graph Neural Networks on Dynamic Link Prediction},
  author={Skarding, Joakim and Hellmich, Matthew and Gabrys, Bogdan and Musial-Gabrys, Katarzyna},
  year={2021}
}
